{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exlcude confusing pairs prior to annotation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 Prepare annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob \n",
    "import os \n",
    "from collections import defaultdict\n",
    "\n",
    "from utils import read_group, read_csv, to_csv\n",
    "\n",
    "def load_pairs(exp_group):\n",
    "    \n",
    "    all_pairs = []\n",
    "    collections = ['perceptual', 'activities', 'complex', 'parts']\n",
    "    prop_coll_dict = read_group(exp_group)\n",
    "    \n",
    "    for collection in collections:\n",
    "        f = f'../data/{collection}.csv'\n",
    "        dict_list = read_csv(f)\n",
    "        for d in dict_list:\n",
    "            prop = d['property']\n",
    "            if prop in prop_coll_dict:\n",
    "                all_pairs.append(d)\n",
    "    return all_pairs\n",
    "\n",
    "def shrink_dict(d, keys):\n",
    "    current_keys = list(d.keys())\n",
    "    for k in current_keys:\n",
    "        if k not in keys:\n",
    "            d.pop(k)\n",
    "    return d\n",
    "            \n",
    "\n",
    "def to_file(all_pairs, exp_group):\n",
    "    header = ['property', 'lemma']\n",
    "    all_pairs_clean = [shrink_dict(d, header) for d in all_pairs]\n",
    "    f = f'../pair_filtering/{exp_group}.csv'\n",
    "    to_csv(f, all_pairs_clean)\n",
    "    \n",
    "    \n",
    "def divide_to_file(exp_group, annotators):\n",
    "    all_pairs = load_pairs(exp_group)\n",
    " \n",
    "    \n",
    "    exp_dir = f'../data_pair_filtering/to_annotate/{exp_group}/'\n",
    "    if not os.path.isdir(exp_dir):\n",
    "        os.mkdir(exp_dir)\n",
    "    \n",
    "    prop_dict = defaultdict(list)\n",
    "    for d in all_pairs:\n",
    "        header = ['property', 'lemma']\n",
    "        d_clean = shrink_dict(d, header) \n",
    "        prop = d_clean['property']\n",
    "        prop_dict[prop].append(d_clean)\n",
    "\n",
    "    for prop, dict_list in prop_dict.items():\n",
    "        for annotator in annotators:\n",
    "            f = f'{exp_dir}/{prop}-{annotator}.csv'\n",
    "            to_csv(f, dict_list)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate annotation sheets - already done \n",
    "#exp_group = 'experiment3'   \n",
    "#annotators = ['pia', 'antske']\n",
    "#divide_to_file(exp_group, annotators)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 Annotate via Google sheets\n",
    "\n",
    "Annotation instructions, links and status overview are [here](https://docs.google.com/document/d/1tupla_Jhr1hXt0CEle0Rji355zZpBZeGXugPMcKRjLM/edit?usp=sharing). \n",
    "\n",
    "Once annotationes are down, download the sheets as .csv files and store in `../pair_filtering/annotated/exp_name/property.csv`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 Analyze agreement "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from utils import read_group, read_csv, to_csv\n",
    "\n",
    "\n",
    "def load_annotations_file(f):\n",
    "    print(f)\n",
    "    dict_list = read_csv(f)\n",
    "    return dict_list\n",
    "\n",
    "\n",
    "def analyze_annotations(exp_group, prop, name1, name2):\n",
    "    \n",
    "    dir_annotated = f'../data_pair_filtering/annotated/{exp_group}'\n",
    "  \n",
    "    f = f'{dir_annotated}/{prop}-{name1}.csv'\n",
    "    dict_list_1 = load_annotations_file(f)\n",
    "    f = f'{dir_annotated}/{prop}-{name2}.csv'\n",
    "    dict_list_2 = load_annotations_file(f)\n",
    "    print(dict_list_2[0].keys())\n",
    "    data_annotated = []\n",
    "    \n",
    "    for d_1, d_2 in zip(dict_list_1, dict_list_2):\n",
    "        new_d = dict()\n",
    "        concept = d_1['lemma']\n",
    "        if concept != d_2['lemma']:\n",
    "            print('problem: data do not match')\n",
    "        l_1 = d_1['decision']\n",
    "        l_2 = d_2['decision']\n",
    "        new_d['lemma'] = concept\n",
    "        new_d[name1] = l_1\n",
    "        new_d[name2] = l_2\n",
    "        if l_1 != l_2:\n",
    "            decision = 'exclude1'\n",
    "            #contradictions.append(new_d)\n",
    "        elif l_1 == l_2 == 'exclude2':\n",
    "            decision = 'exclude'\n",
    "        elif l_1 == l_2 == 'include':\n",
    "            decision = 'include'\n",
    "        new_d['decision'] = decision\n",
    "        data_annotated.append(new_d)\n",
    "            \n",
    "    include = [d for d in data_annotated if d['decision'] == 'include'] \n",
    "    exclude1 = [d for d in data_annotated if d['decision'] == 'exclude1']\n",
    "    exclude_agree = [d for d in data_annotated if d['decision'] == 'exclude2'] \n",
    "    print(f'Total number of concepts: {len(data_annotated)}')\n",
    "    print(f'Total number included by both: {len(include)}')\n",
    "    print(f'Total number excluded by one person: {len(exclude1)}')\n",
    "    print(f'Total number of agreements on exlcude: {len(exclude_agree)}')\n",
    "    if exclude_agree:\n",
    "        print('Agreed on excluding:')\n",
    "        for d in exclude_agree:\n",
    "            print(d['lemma'])\n",
    "    return data_annotated\n",
    "\n",
    "\n",
    "def aggregated_to_file(prop, data_annotated, exp_group):\n",
    "    \n",
    "    dir_path = f'../pair_filtering/aggregated/{exp_group}'\n",
    "    if not os.path.isdir(dir_path):\n",
    "        os.mkdir(dir_path)\n",
    "    \n",
    "    file_path = f'{dir_path}/{prop}.csv'\n",
    "    to_csv(file_path, data_annotated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../data_pair_filtering/annotated/experiment3/blue-antske.csv\n",
      "../data_pair_filtering/annotated/experiment3/blue-pia.csv\n",
      "include include\n",
      "include include\n",
      "include include\n",
      "include include\n",
      "include include\n",
      "include include\n",
      "include include\n",
      "include include\n",
      "include exclude\n",
      "include include\n",
      "include include\n",
      "include include\n",
      "include include\n",
      "include include\n",
      "include include\n",
      "include include\n",
      "include include\n",
      "include include\n",
      "include include\n",
      "include include\n",
      "include include\n",
      "include include\n",
      "include include\n",
      "include include\n",
      "include include\n",
      "include include\n",
      "include include\n",
      "include include\n",
      "include include\n",
      "include include\n",
      "include include\n",
      "include include\n",
      "include include\n",
      "include include\n",
      "include include\n",
      "include include\n",
      "include include\n",
      "include include\n",
      "include include\n",
      "include include\n",
      "include include\n",
      "include include\n",
      "include include\n",
      "include include\n",
      "include exclude\n",
      "include include\n",
      "include include\n",
      "include include\n",
      "include include\n",
      "include include\n",
      "include include\n",
      "include include\n",
      "include include\n",
      "include include\n",
      "include include\n",
      "include include\n",
      "include include\n",
      "include include\n",
      "include include\n",
      "include include\n",
      "include include\n",
      "include include\n",
      "include include\n",
      "include include\n",
      "include include\n",
      "include include\n",
      "include include\n",
      "include include\n",
      "include include\n",
      "include include\n",
      "include include\n",
      "include include\n",
      "include include\n",
      "include include\n",
      "include include\n",
      "include include\n",
      "include include\n",
      "include include\n",
      "include include\n",
      "include include\n",
      "include include\n",
      "include include\n",
      "include exclude\n",
      "include include\n",
      "include include\n",
      "exclude exclude\n",
      "include exclude\n",
      "include include\n",
      "exclude exclude\n",
      "include include\n",
      "include exclude\n",
      "include include\n",
      "include include\n",
      "include exclude\n",
      "include exclude\n",
      "include exclude\n",
      "include exclude\n",
      "include include\n",
      "include include\n",
      "include include\n",
      "include exclude\n",
      "include exclude\n",
      "include include\n",
      "exclude exclude\n",
      "include include\n",
      "include include\n",
      "include include\n",
      "include exclude\n",
      "include include\n",
      "include exclude\n",
      "exclude exclude\n",
      "include include\n",
      "include exclude\n",
      "include exclude\n",
      "exclude exclude\n",
      "exclude exclude\n",
      "include exclude\n",
      "include exclude\n",
      "include include\n",
      "include exclude\n",
      "include include\n",
      "include exclude\n",
      "include exclude\n",
      "include exclude\n",
      "include include\n",
      "include exclude\n",
      "include include\n",
      "include exclude\n",
      "include exclude\n",
      "include include\n",
      "include exclude\n",
      "include exclude\n",
      "include include\n",
      "include exclude\n",
      "include exclude\n",
      "exclude exclude\n",
      "include exclude\n",
      "include exclude\n",
      "include include\n",
      "include exclude\n",
      "exclude exclude\n",
      "include include\n",
      "include exclude\n",
      "Total number of concepts: 143\n",
      "Total number included by both: 106\n",
      "Total number excluded by one person: 37\n",
      "Total number of agreements on exlcude: 0\n",
      "\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../pair_filtering/aggregated/experiment3'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-04cb2e6c7192>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mdata_annotated\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0manalyze_annotations\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexp_group\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0maggregated_to_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_annotated\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexp_group\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-8-8bdf8478dc9f>\u001b[0m in \u001b[0;36maggregated_to_file\u001b[0;34m(prop, data_annotated, exp_group)\u001b[0m\n\u001b[1;32m     59\u001b[0m     \u001b[0mdir_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf'../pair_filtering/aggregated/{exp_group}'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdir_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m         \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmkdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdir_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     62\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0mfile_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf'{dir_path}/{prop}.csv'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../pair_filtering/aggregated/experiment3'"
     ]
    }
   ],
   "source": [
    " \n",
    "exp_group = 'experiment3'\n",
    "name1 = 'antske'\n",
    "name2 = 'pia'\n",
    "prop = 'blue'\n",
    "data_annotated = analyze_annotations(exp_group, prop, name1, name2)\n",
    "print()\n",
    "aggregated_to_file(prop, data_annotated, exp_group)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../pair_filtering/annotated/experiment3/used_in_cooking-antske.csv\n",
      "../pair_filtering/annotated/experiment3/used_in_cooking-pia.csv\n",
      "Total number of concepts: 179\n",
      "Total number included by both: 157\n",
      "Total number excluded by one person: 22\n",
      "Total number of agreements on exlcude: 0\n"
     ]
    }
   ],
   "source": [
    "name1 = 'antske'\n",
    "name2 = 'pia'\n",
    "prop = 'used_in_cooking'\n",
    "data_annotated = analyze_annotations(exp_group, prop, name1, name2)\n",
    "aggregated_to_file(prop, data_annotated, exp_group)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
