{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Replace excluded concepts\n",
    "\n",
    "\n",
    "## Basis: stratified sampling\n",
    "\n",
    "## Steps:\n",
    "* make sure information is up to date (feature_data repo: check if all data are in all files)\n",
    "* recreate bins\n",
    "* analyze dataset in terms of bins\n",
    "* draw from remaining candidates in underrepresented bins \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_lexical_data():\n",
    "    # this is what we originally sampled from\n",
    "    path = '../data_lexical_info/all_lodce_mrc.csv'\n",
    "    \n",
    "    with open(path) as infile:\n",
    "        dicts = list(csv.DictReader(infile))\n",
    "    word_info_dict = defaultdict(list)\n",
    "    for d in dicts:\n",
    "        word = d['word']\n",
    "        word_info_dict[word].append(d)\n",
    "    return word_info_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wiki_frequency {'type': 'distribution', 'mapping': 'log', 'bins': [[4.605170185988092, 9.300147501609214], [9.300147501609214, 13.995124817230336], [13.995124817230336, 18.690102132851457]], 'frequencies': [18678, 6823, 111], 'restriction': None}\n",
      "conc {'type': 'distribution', 'mapping': False, 'bins': [[158.0, 328.66666666666663], [328.66666666666663, 499.3333333333333], [499.3333333333333, 670.0]], 'frequencies': [771, 1476, 1641], 'restriction': None}\n",
      "fam {'type': 'distribution', 'mapping': False, 'bins': [[74.0, 268.33333333333337], [268.33333333333337, 462.6666666666667], [462.6666666666667, 657.0]], 'frequencies': [177, 1321, 2724], 'restriction': None}\n",
      "aoa {'type': 'distribution', 'mapping': False, 'bins': [[125.0, 315.66666666666663], [315.66666666666663, 506.3333333333333], [506.3333333333333, 697.0]], 'frequencies': [416, 964, 488], 'restriction': None}\n",
      "polysemy {'type': 'categories', 'mapping': None, 'bins': ['mon', 'met', 'poly_metonymy', 'homonym'], 'frequencies': [21844, 2339, 8991, 571], 'restriction': None}\n"
     ]
    }
   ],
   "source": [
    "# load general bins\n",
    "\n",
    "\n",
    "with open('../vocabulary_data/bins.json') as infile:\n",
    "    bin_dict_general = json.load(infile)\n",
    "    \n",
    "for k, v in bin_dict_general.items():\n",
    "    print(k, v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "props_collection_dict = {'used_in_cooking': 'complex', 'warm': 'perceptual'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# used_in_cooking\n",
    "p = 'used_in_cooking'\n",
    "coll = props_collection_dict[p]\n",
    "set_info_dict = get_concepts_set(p, coll)\n",
    "lexical_data_dict = load_lexical_data()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'concept_info_dict' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-8f371efc6380>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mconcepts_selected\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'lemma'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0md\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mconcept_dicts_total\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0mtotal_concepts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconcept_info_dict\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0mconcepts_not_selected\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtotal_concepts\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdifference\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconcepts_selected\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m concept_dicts_not_selected = [d for c, d in concept_info_dict.items()\\\n",
      "\u001b[0;31mNameError\u001b[0m: name 'concept_info_dict' is not defined"
     ]
    }
   ],
   "source": [
    "p = 'warm'\n",
    "path = f'../data_pair_filtering/aggregated/experiment3/{p}.csv'\n",
    "\n",
    "with open(path) as infile:\n",
    "    concept_dicts_total = list(csv.DictReader(infile, delimiter = '\\t'))\n",
    "\n",
    "    \n",
    "concept_dicts_include = [d for d in concept_dicts_total if d['decision'] == 'include']\n",
    "concept_dicts_exclude = [d for d in concept_dicts_total\\\n",
    "                         if d['decision'].startswith('exclude')]\n",
    "\n",
    "concepts_selected = set([d['lemma'] for d in concept_dicts_total])\n",
    "total_concepts = set(concept_info_dict.keys())\n",
    "concepts_not_selected = total_concepts.difference(concepts_selected)\n",
    "concept_dicts_not_selected = [d for c, d in concept_info_dict.items()\\\n",
    "                              if c in concepts_not_selected]\n",
    "\n",
    "# sanity check:\n",
    "# should print empty set\n",
    "print(concepts_selected.intersection(concepts_not_selected))\n",
    "print(f'Concepts still available for sampling: {len(concept_dicts_not_selected)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
